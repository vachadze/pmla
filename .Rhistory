fit2 <- lm(mpg ~ ., mtcars)
fit3 <- lm(mpg ~ am + disp + wt + hp, mtcars)
fit4 <- step(lm(mpg ~ ., mtcars))
#plot(fit1)
#anova(fit1)
summary(fit1)
summary(fit2)
summary(fit3)
summary(fit4)
anova(fit1, fit2, fit3, fit4)
mtcars$am %<>% factor(); mtcars$vs %<>% factor(); mtcars$cyl %<>% factor();
mtcars$gear %<>% factor(); mtcars$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars)
fit2 <- lm(mpg ~ ., mtcars)
fit3 <- lm(mpg ~ am + disp + wt + hp, mtcars)
fit4 <- step(lm(mpg ~ ., mtcars))
#plot(fit1)
#anova(fit1)
mtcars$am %<>% factor(); mtcars$vs %<>% factor(); mtcars$cyl %<>% factor();
mtcars$gear %<>% factor(); mtcars$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars)
fit2 <- lm(mpg ~ ., mtcars)
fit3 <- lm(mpg ~ am + disp + wt + hp, mtcars)
fit4 <- step(lm(mpg ~ ., mtcars))
#plot(fit1)
#anova(fit1)
mtcars$am %<>% factor(); mtcars$vs %<>% factor(); mtcars$cyl %<>% factor();
mtcars$gear %<>% factor(); mtcars$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars)
fit2 <- lm(mpg ~ ., mtcars)
fit3 <- lm(mpg ~ am + disp + wt + hp, mtcars)
fit4 <- step(lm(mpg ~ ., mtcars))
#plot(fit1)
#anova(fit1)
library(car)
vif(fit2)
vif(fit3)
vif(fit4)
vif(fit4, fit3)
vif(lm(prestige ~ income + education, data=Duncan))
vif(lm(prestige ~ income + education + type, data=Duncan))
anova(fit3,fit4)
anova(fit3)
anova(fit4)
fit1 <- lm(mpg ~ am, mtcars)
fit2 <- lm(mpg ~ ., mtcars)
fit3 <- lm(mpg ~ disp + hp + wt + am, mtcars)
fit4 <- step(lm(mpg ~ ., mtcars))
anova(fit3)
anova(fit4)
library(datasets)
library(corrplot)
library(magrittr)
library(car)
head(mtcars)
t.test(mpg ~ factor(am), mtcars)
mtcars$am %<>% factor(); mtcars$vs %<>% factor(); mtcars$cyl %<>% factor();
mtcars$gear %<>% factor(); mtcars$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars)
fit2 <- lm(mpg ~ ., mtcars)
fit3 <- lm(mpg ~ disp + hp + wt + am, mtcars)
fit4 <- step(lm(mpg ~ ., mtcars))
vif(fit2)
anova(fit1, fit2, fit3, fit4)
boxplot(mpg ~ am, data = mtcars, col = (c("red","blue")), names = (c("Auto","Manual")),
ylab = "Miles Per Gallon", xlab = "Transmission Type")
str(mtcars)
mt <- cor(mtcars)
library(datasets)
library(corrplot)
library(magrittr)
library(car)
head(mtcars)
t.test(mpg ~ factor(am), mtcars)
mtcars1 <- mtcars
mtcars1$am %<>% factor(); mtcars1$vs %<>% factor(); mtcars1$cyl %<>% factor();
mtcars1$gear %<>% factor(); mtcars1$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars1)
fit2 <- lm(mpg ~ ., mtcars1)
fit3 <- lm(mpg ~ disp + hp + wt + am, mtcars1)
fit4 <- step(lm(mpg ~ ., mtcars1))
vif(fit2)
anova(fit1, fit2, fit3, fit4)
boxplot(mpg ~ am, data = mtcars, col = (c("red","blue")), names = (c("Auto","Manual")),
ylab = "Miles Per Gallon", xlab = "Transmission Type")
str(mtcars)
mt <- cor(mtcars)
rm(mtcars)
rm(mtcars1)
library(datasets)
library(corrplot)
library(magrittr)
library(car)
head(mtcars)
t.test(mpg ~ factor(am), mtcars)
mtcars1 <- mtcars
mtcars1$am %<>% factor(); mtcars1$vs %<>% factor(); mtcars1$cyl %<>% factor();
mtcars1$gear %<>% factor(); mtcars1$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars1)
fit2 <- lm(mpg ~ ., mtcars1)
fit3 <- lm(mpg ~ disp + hp + wt + am, mtcars1)
fit4 <- step(lm(mpg ~ ., mtcars1))
vif(fit2)
anova(fit1, fit2, fit3, fit4)
boxplot(mpg ~ am, data = mtcars, col = (c("red","blue")), names = (c("Auto","Manual")),
ylab = "Miles Per Gallon", xlab = "Transmission Type")
str(mtcars)
mt <- cor(mtcars)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
p.mat <- cor.mtest(mtcars)
corrplot(mt, method = "number", order="FPC", diag = FALSE,
p.mat = p.mat, sig.level = 0.05, insig = "blank")
summary(fit1)
summary(fit2)
summary(fit3)
summary(fit4)
vif(fit3)
vif(fit4)
anova(fit3)
anova(fit4)
par(mfrow=c(2,2))
plot(fit4)
library(datasets)
library(corrplot)
library(magrittr)
library(car)
head(mtcars)
t.test(mpg ~ factor(am), mtcars)
mtcars1 <- mtcars
mtcars1$am %<>% factor(); mtcars1$vs %<>% factor(); mtcars1$cyl %<>% factor();
mtcars1$gear %<>% factor(); mtcars1$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars1)
fit2 <- lm(mpg ~ ., mtcars1)
fit3 <- lm(mpg ~ hp + wt + am, mtcars1)
fit4 <- step(lm(mpg ~ ., mtcars1))
boxplot(mpg ~ am, data = mtcars, col = (c("red","blue")), names = (c("Auto","Manual")),
ylab = "Miles Per Gallon", xlab = "Transmission Type")
str(mtcars)
mt <- cor(mtcars)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
p.mat <- cor.mtest(mtcars)
corrplot(mt, method = "number", order="FPC", diag = FALSE,
p.mat = p.mat, sig.level = 0.05, insig = "blank")
summary(fit1)
summary(fit2)
summary(fit3)
summary(fit4)
vif(fit3)
vif(fit4)
anova(fit3)
anova(fit4)
par(mfrow=c(2,2))
plot(fit4)
vif(fit3)
vif(fit4)
fit3
fit4
anova(fit1, fit3, fit4, fit2)
anova(fit1, fit2)
anova(fit2, fit3)
anova(fit3, fit4)
anova(fit1, fit3)
anova(fit3, fit4)
library(datasets)
library(corrplot)
library(magrittr)
library(car)
head(mtcars)
t.test(mpg ~ factor(am), mtcars)
mtcars1 <- mtcars
mtcars1$am %<>% factor(); mtcars1$vs %<>% factor(); mtcars1$cyl %<>% factor();
mtcars1$gear %<>% factor(); mtcars1$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars1)
fit2 <- lm(mpg ~ ., mtcars1)
fit3 <- lm(mpg ~ hp + wt + am, mtcars1)
fit4 <- step(lm(mpg ~ ., mtcars1))
anova(fit1, fit3, fit4, fit2)
boxplot(mpg ~ am, data = mtcars, col = (c("red","blue")), names = (c("Auto","Manual")),
ylab = "Miles Per Gallon", xlab = "Transmission Type")
str(mtcars)
mt <- cor(mtcars)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
p.mat <- cor.mtest(mtcars)
corrplot(mt, method = "number", order="FPC", diag = FALSE,
p.mat = p.mat, sig.level = 0.05, insig = "blank")
summary(fit1)
summary(fit2)
summary(fit3)
summary(fit4)
par(mfrow=c(2,2))
plot(fit3)
View(shuttle)
library(datasets)
library(corrplot)
library(magrittr)
library(car)
head(mtcars)
t.test(mpg ~ factor(am), mtcars)
mtcars1 <- mtcars
mtcars1$am %<>% factor(); mtcars1$vs %<>% factor(); mtcars1$cyl %<>% factor();
mtcars1$gear %<>% factor(); mtcars1$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars1)
fit2 <- lm(mpg ~ ., mtcars1)
fit3 <- lm(mpg ~ hp + wt + am, mtcars1)
fit4 <- step(lm(mpg ~ ., mtcars1))
anova(fit1, fit3, fit4, fit2)
boxplot(mpg ~ am, data = mtcars, col = (c("red","blue")), names = (c("Auto",Be"Manual")),
library(datasets)
library(corrplot)
library(magrittr)
library(car)
head(mtcars)
t.test(mpg ~ factor(am), mtcars)
mtcars1 <- mtcars
mtcars1$am %<>% factor(); mtcars1$vs %<>% factor(); mtcars1$cyl %<>% factor();
mtcars1$gear %<>% factor(); mtcars1$carb %<>% factor()
fit1 <- lm(mpg ~ am, mtcars1)
fit2 <- lm(mpg ~ ., mtcars1)
fit3 <- lm(mpg ~ hp + wt + am, mtcars1)
fit4 <- step(lm(mpg ~ ., mtcars1))
anova(fit1, fit3, fit4, fit2)
boxplot(mpg ~ am, data = mtcars, col = (c("red","blue")), names = (c("Auto","Manual")),
ylab = "Miles Per Gallon", xlab = "Transmission Type")
str(mtcars)
mt <- cor(mtcars)
cor.mtest <- function(mat, ...) {
mat <- as.matrix(mat)
n <- ncol(mat)
p.mat<- matrix(NA, n, n)
diag(p.mat) <- 0
for (i in 1:(n - 1)) {
for (j in (i + 1):n) {
tmp <- cor.test(mat[, i], mat[, j], ...)
p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
}
}
colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
p.mat
}
p.mat <- cor.mtest(mtcars)
corrplot(mt, method = "number", order="FPC", diag = FALSE,
p.mat = p.mat, sig.level = 0.05, insig = "blank")
summary(fit1)
summary(fit2)
summary(fit3)
summary(fit4)
par(mfrow=c(2,2))
plot(fit3)
str(t.test(mpg ~ factor(am), mtcars))
summary(t.test(mpg ~ factor(am), mtcars))
t.test(mpg ~ factor(am), mtcars)$estimate
t.test(mpg ~ factor(am), mtcars)$conf.int
t.test(mpg ~ factor(am), mtcars)$p.value
print(t.test(mpg ~ factor(am), mtcars)$estimate)
print(t.test(mpg ~ factor(am), mtcars)$conf.int)
t.test
install.packages(c("dplyr", "glue", "R6", "rmarkdown"))
install.packages(c("dplyr", "glue", "R6", "rmarkdown"))
install.packages(c("dplyr", "glue", "R6", "rmarkdown"))
rm(list=ls())
install.packages(c("dplyr", "glue", "R6", "rmarkdown"))
install.packages(c("dplyr", "glue", "R6", "rmarkdown"))
install.packages(c("dplyr", "glue", "R6", "rmarkdown"))
rm(list=ls())
install.packages("AppliedPredictiveModeling")
install.packages(c("bigrquery", "bindrcpp", "brglm", "coin", "curl", "DBI", "dplyr", "evaluate", "globals", "glue", "rvg", "sys"))
?caret
library(caret)
library(AppliedPredictiveModeling)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
predDF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = predDF)
combPred <- predict(combModFit, predDF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(combPred, testing$diagnosis)$overall[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate) # For year() function below
dat = read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/gaData.csv")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
install.packages("forecast")
install.packages("xts")
library(forecast)
ymod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
setwd("~/R/Coursera/r_work/ml/pmla")
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(caret)
train <- read.csv("pml-training.csv")
test <- read.csv("pml-testing.csv")
pml.train <- read.csv("pml-training.csv")
pml.test <- read.csv("pml-testing.csv")
pml.train <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
pml.test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
View(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
View(adData)
pml.test <- pml.test[,8:length(pml.test)] # remove meta-data
pml.train <- pml.train[,8:length(pml.train)] # remove meta-data
nzv <- nearZeroVar(pml.train, saveMetrics = TRUE)
nzv
str(pml.train)
t <- summary(pml.train)
knitr::opts_chunk$set(echo = TRUE)
t <- apply(pml.train, 2, function(x) sum(is.na(x))/nrow(x))
t <- apply(pml.train[,1], 2, function(x) sum(is.na(x))/nrow(x))
t <- apply(pml.train[,1:2], 2, function(x) sum(is.na(x))/nrow(x))
ch <- function(x) sum(is.na(x))/nrow(x)
ch(pml.tran[,1])
ch(pml.train[,1])
ch(pml.train[,2])
ch(pml.train[,5])
sum(is.na(pml.train[,5]))
sum(is.na(pml.train[,5]))/nrow(pml.train[,5])
nrow(pml.train[,5])
NROW(pml.train[,5])
ch <- function(x) sum(is.na(x))/NROW(x)
ch(pml.train[,5])
t <- apply(pml.train[,1:2], 2, function(x) sum(is.na(x))/NROW(x))
t <- apply(pml.train, 2, function(x) sum(is.na(x))/NROW(x))
summary(t)
t
names(t)
t[1]
t[2]
t[2][1]
t[2][2]
t[[2]]
t[[1]]
t[[5]]
t <- as.data.frame(apply(pml.train, 2, function(x) sum(is.na(x))/NROW(x)))
t[[]]<0.95
str(t)
t <- apply(pml.train, 2, function(x) sum(is.na(x))/NROW(x))
str(t)
t[1]
tt <- t(t)
tt
tt <- t(t)
str(t)
tt <- t[t<0.95]
tt
t
names(tt)
t <- apply(pml.train, 2, function(x) sum(is.na(x))/NROW(x)) # check NA percentage
features.names <- names(t[t<0.95]) # leave only columns with no more than 95% on NAs
features.names
pml.train[,features.names]
pml.train <- pml.train[,features.names]
pml.test <- pml.test[,features.names]
pml.test <- pml.test[,features.names]
pml.train <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
pml.test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
identical(names(pml.test), names(pml.train))
pml.test <- pml.test[,features.names[1:length(features.names)-1]]
pml.train <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!",""))
pml.test <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!",""))
pml.test <- pml.test[,8:length(pml.test)] # remove meta-data
pml.train <- pml.train[,8:length(pml.train)] # remove meta-data
t <- apply(pml.train, 2, function(x) sum(is.na(x))/NROW(x)) # check NA percentage
features.names <- names(t[t<0.95]) # leave only columns with no more than 95% on NAs
pml.train <- pml.train[,features.names]
pml.test <- pml.test[,features.names[1:length(features.names)-1]]
nzv <- nearZeroVar(pml.train, saveMetrics = TRUE)
nzv
summary(nzv)
summary(nzv[,c(3:4)]) #check if near zero variance data exists to be removed
knitr::opts_chunk$set(echo = TRUE)
dim(pml.train)
inTrain <- createDataPartition(y=pml.train$classe, p=0.75, list=FALSE)
training <- pml.train[inTrain,]
testing <- pml.train[-inTrain,]
dim(trainig)
dim(training)
dim(testing)
set.seed(1234)
inTrain <- createDataPartition(y=pml.train$classe, p=0.75, list=FALSE)
training <- pml.train[inTrain,]
testing <- pml.train[-inTrain,]
dim(training)
dim(testing)
control <- trainControl(method="repeatedcv", number=10, repeats=3)
set.seed(1234)
modelLda <- train(classe ~ ., data=training, method="lda", trControl=control)
set.seed(1234)
modelGbm <- train(classe ~ ., data=training, method="gbm", trControl=control, verbose=FALSE)
set.seed(1234)
modelRf <- train(classe ~ ., data=training, method="rf", trControl=control)
saveRDS(modelLda, "modelLda.RDS")
saveRDS(modelGbm, "modelGbm.RDS")
saveRDS(modelRf, "modelRf.RDS")
saveRDS(results,"results.RDS")
results <- resamples(list(LDA=modelLda, GBM=modelGbm, RF=modelRf))
saveRDS(results,"results.RDS")
summary(results)
bwplot(results)
dotplot(results)
str(results)
bwplot(resamples(list(GBM=modelGbm, RF=modelRf)))
summary(modelRf)
print(modelRf)
pred_rf <- predict(modelRf, testing)
confusionMatrix(pred_rf, testing$classe)$overall[1]
confusionMatrix(pred_rf, testing$classe)
confusionMatrix(pred_rf, testing$classe)$overall
pml.predict <- predict(mod_rf, pml.test)
pml.predict <- predict(moddelRf, pml.test)
pml.predict <- predict(modelRf, pml.test)
pml.predict
